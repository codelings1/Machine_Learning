{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduling Dataflow Job \n",
    "## using PubSub, Cloud Fuction, Cloud Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Objective](Overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this POC we will be using template.json in bucket. please check BigQ-Sql read me for more info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload [template.json](template.json) in Storage bucket\n",
    "<strong>[Img](bucket1.png)</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open [Cloud Pub/Sub](https://console.cloud.google.com/cloudpubsub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a topic. Set name to <strong>test_pipeline</strong>\n",
    "<p>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Open [Cloud function](https://console.cloud.google.com/functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a new fuction... set name to <strong>function 1</strong>.<br>\n",
    "2. Select Pub/Sub under Trigger option.<br>\n",
    "3. Click dropdown and select the topic <strong>test_pipeline</strong>.<br>\n",
    "4. Edit index.js file to [this](index.js).<br><br><br>\n",
    "<strong>Search dataflow.projects in index file and edit the following:</strong><br><br>\n",
    "dataflow.projects.templates.create({\n",
    "        projectId: 'dark-pipe-247510',  <-------- Project ID\n",
    "        resource: {\n",
    "          parameters: {},\n",
    "          jobName: 'PipelineDF',\n",
    "          gcsPath: 'gs://dark-pipe-247510/template1.json'   <-------Template json location\n",
    "        }\n",
    "<br>\n",
    "5. Change package.json to [this](package.json).\n",
    "6. Set Function or execute : <strong>helloPubSub</strong>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</p>\n",
    "<strong>To check the functionality of cloud function open your pubsub topic and publish a message and then go to Dataflow jobs to check the job status.</strong>\n",
    "<p>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open [Cloud Scheduler](https://console.cloud.google.com/cloudscheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a job\n",
    "2. Set Frequency to :  <strong>* * * * *</strong>\n",
    "3. Target:             <strong>Pub/Sub</strong>\n",
    "4. Topic:              <strong>test_pipeline</strong>    \n",
    "\n",
    "<strong>[Image Source](scheduler2.png)</strong>\n",
    "\n",
    "5. Run the test Scheduler, \" * * * * *\" implies scheduler will trigger pubsub after every 3 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Function Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cloud Function Logs](function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Dataflow Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Dataflow Logs](dataflow2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ParDo function log will return the name and gender from dataset we used in Cloud Sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "References <br>\n",
    "[Easy way to schedule](https://stackoverflow.com/questions/43816707/easiest-way-to-schedule-a-google-cloud-dataflow-job)<br>\n",
    "[CLOUD FAQs](https://cloud.google.com/dataflow/docs/resources/faq)<br>\n",
    "[using App Engine Cron Service](https://cloud.google.com/blog/products/gcp/scheduling-dataflow-pipelines-using-app-engine-cron-service-or-cloud-functions)<br>\n",
    "Different approaches:<strong> [Link](https://tech.travelaudience.com/scheduling-tasks-on-google-cloud-platform-c820fea05249)</strong>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
